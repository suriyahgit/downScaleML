{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393270df-4f61-4cf2-9dd3-0c7c1096e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:26: Initializing downscaling for period: 2014-01-01 - 2015-12-31\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:26: Initializing ERA5 predictors.\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/geopotential, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/temperature, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/u_component_of_wind, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/v_component_of_wind, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/specific_humidity, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/mean_sea_level_pressure, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/p_REANALYSIS/ERA5/2m_temperature, pattern: .nc$\n",
      "downscaleml.core.dataset: Variables: geopotential, temperature, u_component_of_wind, v_component_of_wind, specific_humidity, mean_sea_level_pressure, 2m_temperature\n",
      "downscaleml.core.dataset: Pressure levels (hPa): 500, 850.\n",
      "/home/sdhinakaran/micromamba/envs/check/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.24.2\n",
      "  warnings.warn(\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:28: Initializing observations for predictand: tasmean\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/CERRA/tasmean, pattern: .nc$\n",
      "downscaleml.core.utils: Searching: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/DEM, pattern: ^interTwin_dem.nc$\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:28: Reading digital elevation model: /mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/hydroModelDownscale/DEM/interTwin_dem.nc\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.dataset: Computing terrain slope ...\n",
      "downscaleml.core.dataset: Computing terrain aspect ...\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:28: Initializing training data.\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:28: We are not calculating Stratified Precipitation based on Wet Days here!\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "__main__: Adding day of the year to predictor variables ...\n",
      "downscaleml.core.dataset: Encoding day of the year to cyclical feature ...\n",
      "__main__: Adding day of the year to predictor variables ...\n",
      "downscaleml.core.dataset: Encoding day of the year to cyclical feature ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (time: 730, x: 161, y: 96)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2014-01-01 2014-01-02 ... 2015-12-31\n",
      "  * x          (x) float64 5.084 5.151 5.218 5.285 ... 15.62 15.69 15.76 15.82\n",
      "  * y          (y) float64 43.62 43.69 43.75 43.82 ... 49.8 49.86 49.93 50.0\n",
      "Data variables: (12/17)\n",
      "    z_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    z_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    t_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    t_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    u_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    u_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    ...         ...\n",
      "    t2m        (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    elevation  (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    slope      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    aspect     (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    sin_doy    (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    cos_doy    (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.0.4 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    history:      Fri Dec 08 14:20:05 2023: cdo -O -s -remapbil,/mnt/CEPH_PRO...\n",
      "    CDO:          Climate Data Operators version 2.0.4 (https://mpimet.mpg.de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:29: Shape of the dask.array<transpose, shape=(161, 96, 730, 17), dtype=float32, chunksize=(161, 96, 365, 1), chunktype=numpy.ndarray> is in (spatial, time, variables):(161, 96, 730, 17)\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (time: 365, x: 161, y: 96)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2016-01-01 2016-01-02 ... 2016-12-30\n",
      "  * x          (x) float64 5.084 5.151 5.218 5.285 ... 15.62 15.69 15.76 15.82\n",
      "  * y          (y) float64 43.62 43.69 43.75 43.82 ... 49.8 49.86 49.93 50.0\n",
      "Data variables: (12/17)\n",
      "    z_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    z_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    t_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    t_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    u_500      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    u_850      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    ...         ...\n",
      "    t2m        (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    elevation  (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    slope      (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    aspect     (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    sin_doy    (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "    cos_doy    (time, y, x) float32 dask.array<chunksize=(357, 96, 161), meta=np.ndarray>\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.0.4 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    history:      Fri Dec 08 14:20:05 2023: cdo -O -s -remapbil,/mnt/CEPH_PRO...\n",
      "    CDO:          Climate Data Operators version 2.0.4 (https://mpimet.mpg.de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:47: Shape of the dask.array<transpose, shape=(161, 96, 365, 17), dtype=float32, chunksize=(161, 96, 357, 1), chunktype=numpy.ndarray> is in (spatial, time, variables):(161, 96, 365, 17)\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:56: Shape of the [[[[282.51562]\n",
      "   [284.83865]\n",
      "   [284.09058]\n",
      "   ...\n",
      "   [283.90338]\n",
      "   [281.9838 ]\n",
      "   [283.27625]]\n",
      "\n",
      "  [[282.11453]\n",
      "   [284.16345]\n",
      "   [283.51794]\n",
      "   ...\n",
      "   [283.28622]\n",
      "   [281.8241 ]\n",
      "   [282.96323]]\n",
      "\n",
      "  [[282.27887]\n",
      "   [283.824  ]\n",
      "   [283.46872]\n",
      "   ...\n",
      "   [283.4605 ]\n",
      "   [281.72687]\n",
      "   [283.02945]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[278.4892 ]\n",
      "   [280.05664]\n",
      "   [280.6861 ]\n",
      "   ...\n",
      "   [278.6501 ]\n",
      "   [277.42   ]\n",
      "   [278.915  ]]\n",
      "\n",
      "  [[278.3969 ]\n",
      "   [279.9958 ]\n",
      "   [280.60373]\n",
      "   ...\n",
      "   [278.73074]\n",
      "   [277.64935]\n",
      "   [278.8657 ]]\n",
      "\n",
      "  [[278.55902]\n",
      "   [280.22015]\n",
      "   [280.87073]\n",
      "   ...\n",
      "   [279.11548]\n",
      "   [278.11383]\n",
      "   [279.09467]]]\n",
      "\n",
      "\n",
      " [[[282.05484]\n",
      "   [284.5051 ]\n",
      "   [283.61932]\n",
      "   ...\n",
      "   [283.49448]\n",
      "   [282.04196]\n",
      "   [283.18262]]\n",
      "\n",
      "  [[281.39548]\n",
      "   [283.7295 ]\n",
      "   [283.01083]\n",
      "   ...\n",
      "   [282.71664]\n",
      "   [281.64862]\n",
      "   [282.84674]]\n",
      "\n",
      "  [[281.64978]\n",
      "   [283.25494]\n",
      "   [282.85446]\n",
      "   ...\n",
      "   [282.99188]\n",
      "   [281.556  ]\n",
      "   [282.9004 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[278.35165]\n",
      "   [279.99377]\n",
      "   [280.60767]\n",
      "   ...\n",
      "   [278.45636]\n",
      "   [277.4305 ]\n",
      "   [278.82068]]\n",
      "\n",
      "  [[278.38187]\n",
      "   [280.02347]\n",
      "   [280.64294]\n",
      "   ...\n",
      "   [278.61798]\n",
      "   [277.70142]\n",
      "   [278.8844 ]]\n",
      "\n",
      "  [[278.60657]\n",
      "   [280.29608]\n",
      "   [280.99683]\n",
      "   ...\n",
      "   [279.068  ]\n",
      "   [278.2416 ]\n",
      "   [279.1607 ]]]\n",
      "\n",
      "\n",
      " [[[281.581  ]\n",
      "   [284.13794]\n",
      "   [283.1881 ]\n",
      "   ...\n",
      "   [282.79486]\n",
      "   [282.06378]\n",
      "   [283.18103]]\n",
      "\n",
      "  [[280.92792]\n",
      "   [283.41516]\n",
      "   [282.68875]\n",
      "   ...\n",
      "   [282.2748 ]\n",
      "   [281.4098 ]\n",
      "   [282.6947 ]]\n",
      "\n",
      "  [[280.9433 ]\n",
      "   [282.8189 ]\n",
      "   [282.5608 ]\n",
      "   ...\n",
      "   [282.43948]\n",
      "   [281.23242]\n",
      "   [282.6313 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[278.19736]\n",
      "   [279.9045 ]\n",
      "   [280.51688]\n",
      "   ...\n",
      "   [278.28265]\n",
      "   [277.30673]\n",
      "   [278.7706 ]]\n",
      "\n",
      "  [[278.1448 ]\n",
      "   [279.86346]\n",
      "   [280.5277 ]\n",
      "   ...\n",
      "   [278.45688]\n",
      "   [277.52267]\n",
      "   [278.80884]]\n",
      "\n",
      "  [[278.31757]\n",
      "   [280.06464]\n",
      "   [280.78436]\n",
      "   ...\n",
      "   [278.89792]\n",
      "   [278.01764]\n",
      "   [278.99335]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[285.56808]\n",
      "   [286.33884]\n",
      "   [287.5714 ]\n",
      "   ...\n",
      "   [283.73114]\n",
      "   [282.2793 ]\n",
      "   [280.87457]]\n",
      "\n",
      "  [[284.4934 ]\n",
      "   [285.28354]\n",
      "   [287.1138 ]\n",
      "   ...\n",
      "   [282.8233 ]\n",
      "   [281.50806]\n",
      "   [279.89133]]\n",
      "\n",
      "  [[284.183  ]\n",
      "   [284.48578]\n",
      "   [286.59024]\n",
      "   ...\n",
      "   [281.72534]\n",
      "   [280.90298]\n",
      "   [279.14316]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[274.78955]\n",
      "   [274.9382 ]\n",
      "   [276.2185 ]\n",
      "   ...\n",
      "   [275.8186 ]\n",
      "   [272.34702]\n",
      "   [269.05243]]\n",
      "\n",
      "  [[275.5313 ]\n",
      "   [275.55103]\n",
      "   [277.08206]\n",
      "   ...\n",
      "   [276.39297]\n",
      "   [273.06372]\n",
      "   [270.25583]]\n",
      "\n",
      "  [[275.86078]\n",
      "   [275.73044]\n",
      "   [276.75616]\n",
      "   ...\n",
      "   [276.63394]\n",
      "   [273.5679 ]\n",
      "   [270.96985]]]\n",
      "\n",
      "\n",
      " [[[286.02164]\n",
      "   [286.78345]\n",
      "   [287.62244]\n",
      "   ...\n",
      "   [283.33923]\n",
      "   [282.52258]\n",
      "   [281.18152]]\n",
      "\n",
      "  [[284.75146]\n",
      "   [285.45398]\n",
      "   [287.1417 ]\n",
      "   ...\n",
      "   [282.21143]\n",
      "   [281.58405]\n",
      "   [280.01953]]\n",
      "\n",
      "  [[283.2431 ]\n",
      "   [283.3747 ]\n",
      "   [285.81354]\n",
      "   ...\n",
      "   [280.20093]\n",
      "   [280.37622]\n",
      "   [278.4535 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[274.9413 ]\n",
      "   [275.03394]\n",
      "   [276.4929 ]\n",
      "   ...\n",
      "   [275.8227 ]\n",
      "   [272.28558]\n",
      "   [269.1985 ]]\n",
      "\n",
      "  [[275.75818]\n",
      "   [275.70004]\n",
      "   [277.1431 ]\n",
      "   ...\n",
      "   [276.49472]\n",
      "   [273.15222]\n",
      "   [270.46503]]\n",
      "\n",
      "  [[275.98505]\n",
      "   [275.8806 ]\n",
      "   [276.71143]\n",
      "   ...\n",
      "   [276.5924 ]\n",
      "   [273.52173]\n",
      "   [270.9557 ]]]\n",
      "\n",
      "\n",
      " [[[285.8796 ]\n",
      "   [286.6932 ]\n",
      "   [287.4325 ]\n",
      "   ...\n",
      "   [282.66037]\n",
      "   [282.48425]\n",
      "   [281.2801 ]]\n",
      "\n",
      "  [[283.917  ]\n",
      "   [284.54178]\n",
      "   [286.51724]\n",
      "   ...\n",
      "   [280.82913]\n",
      "   [280.9007 ]\n",
      "   [279.1998 ]]\n",
      "\n",
      "  [[282.72858]\n",
      "   [282.96176]\n",
      "   [285.32916]\n",
      "   ...\n",
      "   [278.7125 ]\n",
      "   [280.0391 ]\n",
      "   [277.76974]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[275.24484]\n",
      "   [275.29663]\n",
      "   [276.72186]\n",
      "   ...\n",
      "   [275.9916 ]\n",
      "   [272.44064]\n",
      "   [269.5251 ]]\n",
      "\n",
      "  [[275.89966]\n",
      "   [275.79337]\n",
      "   [277.0516 ]\n",
      "   ...\n",
      "   [276.48108]\n",
      "   [273.21777]\n",
      "   [270.62964]]\n",
      "\n",
      "  [[276.05127]\n",
      "   [275.9914 ]\n",
      "   [276.64316]\n",
      "   ...\n",
      "   [276.41507]\n",
      "   [273.404  ]\n",
      "   [270.89322]]]] is in (spatial, time, variables):(161, 96, 730, 1)\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:57: Shape of the [[[[283.21368]\n",
      "   [283.48727]\n",
      "   [279.15448]\n",
      "   ...\n",
      "   [278.6078 ]\n",
      "   [279.0213 ]\n",
      "   [280.28564]]\n",
      "\n",
      "  [[282.8888 ]\n",
      "   [283.00598]\n",
      "   [279.168  ]\n",
      "   ...\n",
      "   [277.71628]\n",
      "   [278.52975]\n",
      "   [279.9828 ]]\n",
      "\n",
      "  [[282.70422]\n",
      "   [283.00885]\n",
      "   [278.82224]\n",
      "   ...\n",
      "   [276.92126]\n",
      "   [277.19748]\n",
      "   [279.4099 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[277.5308 ]\n",
      "   [278.8822 ]\n",
      "   [277.50363]\n",
      "   ...\n",
      "   [271.80185]\n",
      "   [272.6251 ]\n",
      "   [270.2873 ]]\n",
      "\n",
      "  [[277.6755 ]\n",
      "   [279.00735]\n",
      "   [277.53552]\n",
      "   ...\n",
      "   [272.0476 ]\n",
      "   [272.5168 ]\n",
      "   [270.981  ]]\n",
      "\n",
      "  [[277.9395 ]\n",
      "   [279.37744]\n",
      "   [277.71768]\n",
      "   ...\n",
      "   [272.13858]\n",
      "   [272.58664]\n",
      "   [271.69836]]]\n",
      "\n",
      "\n",
      " [[[282.97577]\n",
      "   [283.1912 ]\n",
      "   [279.02106]\n",
      "   ...\n",
      "   [277.97784]\n",
      "   [278.08917]\n",
      "   [279.9807 ]]\n",
      "\n",
      "  [[282.6394 ]\n",
      "   [282.77783]\n",
      "   [278.79272]\n",
      "   ...\n",
      "   [276.7697 ]\n",
      "   [277.1607 ]\n",
      "   [279.42465]]\n",
      "\n",
      "  [[282.3681 ]\n",
      "   [282.56995]\n",
      "   [278.37418]\n",
      "   ...\n",
      "   [276.7715 ]\n",
      "   [277.149  ]\n",
      "   [279.58813]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[277.6027 ]\n",
      "   [278.8677 ]\n",
      "   [277.4776 ]\n",
      "   ...\n",
      "   [271.81494]\n",
      "   [272.6969 ]\n",
      "   [270.4631 ]]\n",
      "\n",
      "  [[277.7439 ]\n",
      "   [279.06583]\n",
      "   [277.5715 ]\n",
      "   ...\n",
      "   [271.98715]\n",
      "   [272.6224 ]\n",
      "   [271.06454]]\n",
      "\n",
      "  [[278.06857]\n",
      "   [279.47693]\n",
      "   [277.8111 ]\n",
      "   ...\n",
      "   [272.0462 ]\n",
      "   [272.7268 ]\n",
      "   [271.71545]]]\n",
      "\n",
      "\n",
      " [[[282.70007]\n",
      "   [282.92914]\n",
      "   [279.01062]\n",
      "   ...\n",
      "   [278.0924 ]\n",
      "   [277.74414]\n",
      "   [279.77347]]\n",
      "\n",
      "  [[282.29837]\n",
      "   [282.62024]\n",
      "   [278.76175]\n",
      "   ...\n",
      "   [276.95642]\n",
      "   [276.7909 ]\n",
      "   [279.11688]]\n",
      "\n",
      "  [[282.02997]\n",
      "   [282.34103]\n",
      "   [278.32944]\n",
      "   ...\n",
      "   [277.31403]\n",
      "   [277.22528]\n",
      "   [279.21228]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[277.5351 ]\n",
      "   [278.82278]\n",
      "   [277.39417]\n",
      "   ...\n",
      "   [271.85358]\n",
      "   [272.83786]\n",
      "   [270.5849 ]]\n",
      "\n",
      "  [[277.6177 ]\n",
      "   [279.00287]\n",
      "   [277.39508]\n",
      "   ...\n",
      "   [272.03342]\n",
      "   [272.80087]\n",
      "   [271.36133]]\n",
      "\n",
      "  [[277.89215]\n",
      "   [279.32904]\n",
      "   [277.62405]\n",
      "   ...\n",
      "   [272.03293]\n",
      "   [272.8092 ]\n",
      "   [271.84872]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[281.8617 ]\n",
      "   [284.36606]\n",
      "   [280.6049 ]\n",
      "   ...\n",
      "   [284.02905]\n",
      "   [279.74222]\n",
      "   [279.5851 ]]\n",
      "\n",
      "  [[280.38226]\n",
      "   [282.97595]\n",
      "   [279.66812]\n",
      "   ...\n",
      "   [283.38736]\n",
      "   [279.1525 ]\n",
      "   [278.79752]]\n",
      "\n",
      "  [[279.45255]\n",
      "   [281.79102]\n",
      "   [279.00702]\n",
      "   ...\n",
      "   [282.39795]\n",
      "   [278.49655]\n",
      "   [278.08984]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[271.02527]\n",
      "   [271.62064]\n",
      "   [266.65253]\n",
      "   ...\n",
      "   [273.44208]\n",
      "   [269.21707]\n",
      "   [269.01895]]\n",
      "\n",
      "  [[271.63745]\n",
      "   [272.32242]\n",
      "   [267.86795]\n",
      "   ...\n",
      "   [274.60736]\n",
      "   [270.02896]\n",
      "   [269.3004 ]]\n",
      "\n",
      "  [[271.7281 ]\n",
      "   [272.5501 ]\n",
      "   [268.3673 ]\n",
      "   ...\n",
      "   [275.1214 ]\n",
      "   [270.5961 ]\n",
      "   [269.62183]]]\n",
      "\n",
      "\n",
      " [[[282.40292]\n",
      "   [284.7775 ]\n",
      "   [280.84518]\n",
      "   ...\n",
      "   [284.023  ]\n",
      "   [279.90155]\n",
      "   [279.88464]]\n",
      "\n",
      "  [[280.67886]\n",
      "   [283.0459 ]\n",
      "   [279.81335]\n",
      "   ...\n",
      "   [283.30597]\n",
      "   [279.20114]\n",
      "   [278.91766]]\n",
      "\n",
      "  [[278.31442]\n",
      "   [280.49582]\n",
      "   [278.4663 ]\n",
      "   ...\n",
      "   [281.67407]\n",
      "   [278.22256]\n",
      "   [277.7113 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[271.13333]\n",
      "   [271.59354]\n",
      "   [266.772  ]\n",
      "   ...\n",
      "   [273.82556]\n",
      "   [269.42328]\n",
      "   [269.08575]]\n",
      "\n",
      "  [[271.68854]\n",
      "   [272.3635 ]\n",
      "   [267.98288]\n",
      "   ...\n",
      "   [274.8423 ]\n",
      "   [270.24994]\n",
      "   [269.40308]]\n",
      "\n",
      "  [[271.6016 ]\n",
      "   [272.44495]\n",
      "   [268.24487]\n",
      "   ...\n",
      "   [275.11047]\n",
      "   [270.47406]\n",
      "   [269.75323]]]\n",
      "\n",
      "\n",
      " [[[282.27893]\n",
      "   [284.19778]\n",
      "   [280.63937]\n",
      "   ...\n",
      "   [283.74387]\n",
      "   [279.94965]\n",
      "   [279.70126]]\n",
      "\n",
      "  [[279.4243 ]\n",
      "   [281.70856]\n",
      "   [279.2387 ]\n",
      "   ...\n",
      "   [282.54376]\n",
      "   [278.88217]\n",
      "   [278.43378]]\n",
      "\n",
      "  [[277.38126]\n",
      "   [279.71844]\n",
      "   [278.19006]\n",
      "   ...\n",
      "   [281.27966]\n",
      "   [278.2743 ]\n",
      "   [277.62097]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[271.29803]\n",
      "   [271.73154]\n",
      "   [267.06638]\n",
      "   ...\n",
      "   [274.22717]\n",
      "   [269.83063]\n",
      "   [269.1854 ]]\n",
      "\n",
      "  [[271.65753]\n",
      "   [272.37396]\n",
      "   [268.06375]\n",
      "   ...\n",
      "   [274.90488]\n",
      "   [270.46106]\n",
      "   [269.42554]]\n",
      "\n",
      "  [[271.43454]\n",
      "   [272.28937]\n",
      "   [268.078  ]\n",
      "   ...\n",
      "   [275.04083]\n",
      "   [270.3471 ]\n",
      "   [269.78995]]]] is in (spatial, time, variables):(161, 96, 365, 1)\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:57: Dask computations done!\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n",
      "downscaleml.core.utils: 2024-02-14T12:07:57: Downscaling by Random Forest Starts: iterating each grid cell over time dimension\n",
      "downscaleml.core.utils: --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# builtins\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "from logging.config import dictConfig\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# externals\n",
    "import xarray as xr\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# locals\n",
    "from downscaleml.core.dataset import ERA5Dataset, NetCDFDataset, EoDataset\n",
    "\n",
    "from downscaleml.main.config import (NET, ERA5_PLEVELS, ERA5_PREDICTORS, PREDICTAND,\n",
    "                                     CALIB_PERIOD, VALID_PERIOD, DOY, NORM,\n",
    "                                     OVERWRITE, DEM, DEM_FEATURES, STRATIFY,\n",
    "                                     WET_DAY_THRESHOLD, VALID_SIZE, \n",
    "                                     start_year, end_year, CHUNKS)\n",
    "\n",
    "from downscaleml.main.inputoutput import (ERA5_PATH, OBS_PATH, DEM_PATH, MODEL_PATH, TARGET_PATH)\n",
    "\n",
    "from downscaleml.core.constants import (ERA5_P_VARIABLES, ERA5_P_VARIABLES_SHORTCUT, ERA5_P_VARIABLE_NAME,\n",
    "                                        ERA5_S_VARIABLES, ERA5_S_VARIABLES_SHORTCUT, ERA5_S_VARIABLE_NAME,\n",
    "                                        ERA5_VARIABLES, ERA5_VARIABLE_NAMES, ERA5_PRESSURE_LEVELS,\n",
    "                                        PREDICTANDS, ERA5_P_VARIABLES, ERA5_S_VARIABLES)\n",
    "\n",
    "from downscaleml.core.utils import NAMING_Model, normalize, search_files, LogConfig\n",
    "from downscaleml.core.logging import log_conf\n",
    "    \n",
    "# module level logger\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "def stacker(xarray_dataset):\n",
    "    # stack along the lat and lon dimensions\n",
    "    stacked = xarray_dataset.stack()\n",
    "    dask_arr = stacked.to_array().data\n",
    "    xarray_dataset = dask_arr.T\n",
    "    LogConfig.init_log('Shape of the {} is in (spatial, time, variables):{}'.format(xarray_dataset, xarray_dataset.shape))\n",
    "    return xarray_dataset\n",
    "\n",
    "def doy_encoding(X, y=None, doy=False):\n",
    "\n",
    "    # whether to include the day of the year as predictor variable\n",
    "    if doy:\n",
    "        # add doy to set of predictor variables\n",
    "        LOGGER.info('Adding day of the year to predictor variables ...')\n",
    "        X = X.assign(EoDataset.encode_doys(X, chunks=X.chunks))\n",
    "\n",
    "    print(X)\n",
    "    return X\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # initialize timing\n",
    "    start_time = time.monotonic()\n",
    "        \n",
    "    # initialize network filename\n",
    "    state_file = NAMING_Model.state_file(\n",
    "        NET, PREDICTAND, ERA5_PREDICTORS, ERA5_PLEVELS, WET_DAY_THRESHOLD, dem=DEM,\n",
    "        dem_features=DEM_FEATURES, doy=DOY, stratify=STRATIFY)\n",
    "    \n",
    "    state_file = MODEL_PATH.joinpath(PREDICTAND, state_file)\n",
    "    target = TARGET_PATH.joinpath(PREDICTAND)\n",
    "\n",
    "    # check if output path exists\n",
    "    if not target.exists():\n",
    "        target.mkdir(parents=True, exist_ok=True)\n",
    "    # initialize logging\n",
    "    log_file = state_file.with_name(state_file.name + \"_log.txt\")\n",
    "    \n",
    "    if log_file.exists():\n",
    "        log_file.unlink()\n",
    "    dictConfig(log_conf(log_file))\n",
    "\n",
    "    # check if target dataset already exists\n",
    "    target = target.joinpath(state_file.name + '.nc')\n",
    "    if target.exists() and not OVERWRITE:\n",
    "        LogConfig.init_log('{} already exists.'.format(target))\n",
    "        sys.exit()\n",
    "\n",
    "    LogConfig.init_log('Initializing downscaling for period: {}'.format(\n",
    "        ' - '.join([str(CALIB_PERIOD[0]), str(CALIB_PERIOD[-1])])))\n",
    "\n",
    "    # initialize ERA5 predictor dataset\n",
    "    LogConfig.init_log('Initializing ERA5 predictors.')\n",
    "    Era5 = ERA5Dataset(ERA5_PATH.joinpath('ERA5'), ERA5_PREDICTORS,\n",
    "                       plevels=ERA5_PLEVELS)\n",
    "    Era5_ds = Era5.merge(chunks=CHUNKS)\n",
    "    Era5_ds = Era5_ds.rename({'lon': 'x','lat': 'y'})\n",
    "    \n",
    "    # initialize OBS predictand dataset\n",
    "    LogConfig.init_log('Initializing observations for predictand: {}'\n",
    "                       .format(PREDICTAND))\n",
    "\n",
    "    # read in-situ gridded observations\n",
    "    Obs_ds = search_files(OBS_PATH.joinpath(PREDICTAND), '.nc$').pop()\n",
    "    Obs_ds = xr.open_dataset(Obs_ds)\n",
    "    Obs_ds = Obs_ds.rename({'lon': 'x','lat': 'y'})\n",
    "\n",
    "    # whether to use digital elevation model\n",
    "    if DEM:\n",
    "        # digital elevation model: Copernicus EU-Dem v1.1\n",
    "        dem = search_files(DEM_PATH, '^interTwin_dem.nc$').pop()\n",
    "\n",
    "        # read elevation and compute slope and aspect\n",
    "        dem = ERA5Dataset.dem_features(\n",
    "            dem, {'y': Era5_ds.y, 'x': Era5_ds.x},\n",
    "            add_coord={'time': Era5_ds.time})\n",
    "\n",
    "        # check whether to use slope and aspect\n",
    "        if not DEM_FEATURES:\n",
    "            dem = dem.drop_vars(['slope', 'aspect']).chunk(Era5_ds.chunks)\n",
    "\n",
    "        # add dem to set of predictor variables\n",
    "        dem = dem.chunk(Era5_ds.chunks)\n",
    "        Era5_ds = xr.merge([Era5_ds, dem])\n",
    "\n",
    "    # initialize training data\n",
    "    LogConfig.init_log('Initializing training data.')\n",
    "\n",
    "    # split calibration period into training and validation period\n",
    "    if PREDICTAND == 'pr' and STRATIFY:\n",
    "        # stratify training and validation dataset by number of\n",
    "        # observed wet days for precipitation\n",
    "        wet_days = (Obs_ds.sel(time=CALIB_PERIOD).mean(dim=('y', 'x'))\n",
    "                    >= WET_DAY_THRESHOLD).to_array().values.squeeze()\n",
    "        train, valid = train_test_split(\n",
    "            CALIB_PERIOD, stratify=wet_days, test_size=VALID_SIZE)\n",
    "\n",
    "        # sort chronologically\n",
    "        train, valid = sorted(train), sorted(valid)\n",
    "        Era5_train, Obs_train = Era5_ds.sel(time=train), Obs_ds.sel(time=train)\n",
    "        Era5_valid, Obs_valid = Era5_ds.sel(time=valid), Obs_ds.sel(time=valid)\n",
    "    else:\n",
    "        LogConfig.init_log('We are not calculating Stratified Precipitation based on Wet Days here!')\n",
    "\n",
    "    # training and validation dataset\n",
    "    Era5_train, Obs_train = Era5_ds.sel(time=CALIB_PERIOD), Obs_ds.sel(time=CALIB_PERIOD)\n",
    "    Era5_valid, Obs_valid = Era5_ds.sel(time=VALID_PERIOD), Obs_ds.sel(time=VALID_PERIOD)\n",
    "\n",
    "    Era5_train = doy_encoding(Era5_train, Obs_train, doy=DOY)\n",
    "    Era5_valid = doy_encoding(Era5_valid, Obs_valid, doy=DOY)\n",
    "\n",
    "    predictors_train = Era5_train\n",
    "    predictors_valid = Era5_valid\n",
    "    predictand_train = Obs_train\n",
    "    predictand_valid = Obs_valid\n",
    "    \n",
    "    predictors_train = stacker(predictors_train).compute()\n",
    "    predictors_valid = stacker(predictors_valid).compute()\n",
    "    predictand_train = stacker(predictand_train)\n",
    "    predictand_valid = stacker(predictand_valid)\n",
    "    \n",
    "    LogConfig.init_log('Dask computations done!')\n",
    "    # iterate over the grid points\n",
    "    LogConfig.init_log('Downscaling by Random Forest Starts: iterating each grid cell over time dimension')\n",
    "    \n",
    "    Models = {\n",
    "        'RandomForestRegressor' : RandomForestRegressor,\n",
    "        'XGBRegressor' : XGBRegressor,\n",
    "        'AdaBoostRegressor': AdaBoostRegressor,\n",
    "        'LGBMRegressor': LGBMRegressor,\n",
    "    }\n",
    "    Model_name = NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6713f8-2339-4774-a31c-1a37d582ddc7",
   "metadata": {},
   "source": [
    "CV Steps - 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64fcb45b-ed2e-4d92-b355-66c3806f5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "combination = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe2e42f5-7de2-4177-9a79-b6395df99322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_creator(combinations, numpy_object):\n",
    "    gridded = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations)), numpy_object.shape[2], numpy_object.shape[3])) * np.nan\n",
    "    return gridded\n",
    "\n",
    "#predictors_train_grid = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations)), predictors_train.shape[2], predictors_train.shape[3])) * np.nan\n",
    "#predictand_train_grid = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations)), predictand_train.shape[2], predictand_train.shape[3])) * np.nan\n",
    "#predictors_valid_grid = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations)), predictors_valid.shape[2], predictors_valid.shape[3])) * np.nan\n",
    "#predictand_valid_grid = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations)), predictand_valid.shape[2], predictand_valid.shape[3])) * np.nan\n",
    "\n",
    "predictors_train_grid = grid_creator(combination, predictors_train)\n",
    "predictand_train_grid = grid_creator(combination, predictand_train)\n",
    "predictors_valid_grid = grid_creator(combination, predictors_valid)\n",
    "predictand_valid_grid = grid_creator(combination, predictand_valid)\n",
    "\n",
    "x_range = (0, 161)\n",
    "y_range = (0, 96)\n",
    "random.seed(42)\n",
    "\n",
    "dummy_array = np.ones(shape=(int(math.sqrt(combinations)), int(math.sqrt(combinations))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b930ff29-58d0-4775-85bd-56dcdfe3eeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b40814a-ffa3-4dc9-b25e-d93eadde733f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43marray\u001b[49m(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;241m20\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(combination):\n",
    "    x = random.randint(*x_range)\n",
    "    y = random.randint(*y_range)\n",
    "    list.append((x, y))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3380eb5-a828-4a72-a3cb-6a77a8397ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(math.sqrt(combination))):\n",
    "    for j in range(int(math.sqrt(combination))):\n",
    "        predictors_train_grid = \n",
    "        predictand_train_grid = \n",
    "        predictors_valid_grid =  \n",
    "        predictand_valid_grid = \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6518e9-6780-4383-b515-2e1f9a8059ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHECK",
   "language": "python",
   "name": "check"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
