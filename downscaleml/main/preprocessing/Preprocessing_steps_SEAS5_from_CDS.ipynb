{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81822cf6-70c7-43df-ac69-a14e38fcb7d8",
   "metadata": {},
   "source": [
    "Pre-Processing Steps for Seasonal Forecast Data Downloaded from CDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4858b-fde7-4510-9774-c510bee2a649",
   "metadata": {},
   "source": [
    "This code will create similar folders as in the ERA5 for the to be downloaded seasonal forecast files, mind it for the pressure level variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42c9a6-ae8f-4330-882f-c487cba8bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# specify the source and destination paths\n",
    "src_path = \"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/SEAS5\"\n",
    "dst_path = \"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/dailySEAS5\"\n",
    "\n",
    "# use os.walk() to iterate through all directories and subdirectories in the source path\n",
    "for root, dirs, files in os.walk(src_path):\n",
    "\n",
    "    # create the corresponding directory structure in the destination path\n",
    "    for directory in dirs:\n",
    "        src_dir = os.path.join(root, directory)\n",
    "        dst_dir = src_dir.replace(src_path, dst_path)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508e25c-1591-412a-9d8e-7cd06e468b85",
   "metadata": {},
   "source": [
    "This cell will create similar path and also regrid all the files and place them accordingly in their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88ade4-b9e1-4e88-8665-20d3736df088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# specify the source and destination paths\n",
    "src_path = \"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/test_sf/Downloads\"\n",
    "dst_path = \"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/test_sf/Processed\"\n",
    "\n",
    "# use os.walk() to iterate through all directories and subdirectories in the source path\n",
    "for root, dirs, files in os.walk(src_path):\n",
    "    # create the corresponding directory structure in the destination path\n",
    "    for directory in dirs:\n",
    "        src_dir = os.path.join(root, directory)\n",
    "        dst_dir = src_dir.replace(src_path, dst_path)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    # process each file in the current directory\n",
    "    for file in files:\n",
    "        if file.endswith(\".nc\"):  # You can specify the file extension you want to process\n",
    "            src_file = os.path.join(root, file)\n",
    "            dst_file = src_file.replace(src_path, dst_path)\n",
    "            \n",
    "            # Modify the destination file name to include \"_gridded\" before the extension\n",
    "            base_name, extension = os.path.splitext(dst_file)\n",
    "            dst_file = f\"{base_name}_gridded{extension}\"\n",
    "            \n",
    "            # Run the cdo command to process the file and save the output in the destination directory\n",
    "            cdo_command = f\"cdo remapbil,/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/DEM/interTwin_dem.nc {src_file} {dst_file}\"\n",
    "            try:\n",
    "                subprocess.run(cdo_command, shell=True, check=True)\n",
    "                print(f\"Processed: {src_file}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error processing {src_file}: {e}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbd864-ab9c-4cf4-8112-f41fab95f7b2",
   "metadata": {},
   "source": [
    "For Pressure Level Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55892a-d5b9-4c49-a995-d99f5ee99705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds1 = xr.open_dataset(\"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/SEAS5/v_component_of_wind/500/date_2016-01-01_gridded.nc\")\n",
    "ds2 = xr.open_dataset(\"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/SEAS5/v_component_of_wind/850/date_2016-01-01_gridded.nc\")\n",
    "\n",
    "#Joining by a new dimension 'level'\n",
    "combined_ds = xr.concat([ds1, ds2], dim='level')\n",
    "\n",
    "#Providing name for the joined dataset in the dimension 'level'\n",
    "combined_ds['level'] = xr.DataArray([500, 850], dims='level')\n",
    "\n",
    "#Converting the datatype of level so as to match the ERA5\n",
    "combined_ds['level'] = combined_ds['level'].astype('int32')\n",
    "\n",
    "#Streamlining the same order of the index that the other preprocesors has \n",
    "desired_order = ['time', 'level', 'y', 'x', 'number']\n",
    "ds = combined_ds.transpose(*desired_order)\n",
    "\n",
    "#For all the pressure level variables, we use only mean\n",
    "ds = ds.resample(time='D').mean(dim='time')\n",
    "\n",
    "ds.to_netcdf(\"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/dailySEAS5/v_component_of_wind/SEAS5_coarse_v_component_of_wind_2016_01.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df3407-9917-441b-81f7-87081659bc01",
   "metadata": {},
   "source": [
    "For Single Level Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3382b5-2026-4dd1-8d57-4f50922a9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/SEAS5/2m_temperature/date_2016-01-01_gridded.nc\")\n",
    "\n",
    "#Streamlining the same order of the index that the other preprocesors has \n",
    "desired_order = ['time', 'y', 'x', 'number']\n",
    "ds = ds.transpose(*desired_order)\n",
    "\n",
    "#For single level variables, we have to deal with 2m_temperature and total_precipitation, so use the resampler accordingly\n",
    "ds = ds.resample(time='D').mean(dim='time')\n",
    "#ds = ds.resample(time='D').sum(dim='time')*1000\n",
    "\n",
    "ds.to_netcdf(\"/mnt/CEPH_PROJECTS/InterTwin/Climate_Downscaling/larger_alps/SampleSF/dailySEAS5/v_component_of_wind/SEAS5_coarse_v_component_of_wind_2016_01.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_resolution",
   "language": "python",
   "name": "climax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
